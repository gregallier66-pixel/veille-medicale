import streamlit as st
import google.generativeai as genai
import requests
from datetime import datetime, date
import xml.etree.ElementTree as ET
from fpdf import FPDF
import io
import pypdf
from io import BytesIO
import re
import time

st.set_page_config(page_title="Veille M√©dicale Pro", layout="wide")

try:
    G_KEY = st.secrets["GEMINI_KEY"]
except:
    st.error("‚ö†Ô∏è Cl√© GEMINI_KEY manquante")
    st.stop()

DEEPL_KEY = st.secrets.get("DEEPL_KEY", None)

TRAD = {
    "Gyn√©cologie": "Gynecology",
    "Obst√©trique": "Obstetrics",
    "Anesth√©sie-R√©animation": "Anesthesiology",
    "Endocrinologie": "Endocrinology",
    "M√©decine G√©n√©rale": "General Medicine",
    "Chirurgie Gyn√©cologique": "Gynecologic Surgery",
    "Infertilit√©": "Infertility",
    "√âchographie Gyn√©cologique": "Gynecologic Ultrasound",
    "Oncologie": "Oncology",
    "P√©diatrie": "Pediatrics"
}

TYPES_ETUDE = {
    "Tous": "",
    "Essais cliniques": "Clinical Trial",
    "M√©ta-analyses": "Meta-Analysis",
    "Revues syst√©matiques": "Systematic Review",
    "√âtudes de cohorte": "Cohort Studies",
    "√âtudes cas-t√©moins": "Case-Control Studies"
}

JOURNAUX_SPECIALITE = {
    "Gyn√©cologie": ["BJOG", "Obstet Gynecol", "Am J Obstet Gynecol", "Hum Reprod", "Fertil Steril"],
    "Obst√©trique": ["BJOG", "Obstet Gynecol", "Am J Obstet Gynecol", "Ultrasound Obstet Gynecol"],
    "Anesth√©sie-R√©animation": ["Anesthesiology", "Br J Anaesth", "Anesth Analg"],
    "Endocrinologie": ["J Clin Endocrinol Metab", "Diabetes Care", "Eur J Endocrinol"],
    "M√©decine G√©n√©rale": ["BMJ", "JAMA", "N Engl J Med", "Lancet"],
    "Chirurgie Gyn√©cologique": ["Gynecol Surg", "J Minim Invasive Gynecol"],
    "Infertilit√©": ["Fertil Steril", "Hum Reprod"],
    "√âchographie Gyn√©cologique": ["Ultrasound Obstet Gynecol", "J Ultrasound Med"],
    "Oncologie": ["J Clin Oncol", "Lancet Oncol", "Cancer"],
    "P√©diatrie": ["Pediatrics", "JAMA Pediatr"]
}

SOURCES_PAR_SPECIALITE = {
    "Gyn√©cologie": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "Coll√®ge National des Gyn√©cologues Obst√©triciens Fran√ßais", "recherche": "http://www.cngof.fr/?s="},
        "ACOG": {"url": "https://www.acog.org", "description": "American College of Obstetricians and Gynecologists", "recherche": "https://www.acog.org/search?q="},
        "RCOG": {"url": "https://www.rcog.org.uk", "description": "Royal College UK", "recherche": "https://www.rcog.org.uk/search?q="},
        "HAS": {"url": "https://www.has-sante.fr", "description": "Haute Autorit√© de Sant√©", "recherche": "https://www.has-sante.fr/jcms/recherche?text="},
        "SOGC": {"url": "https://www.sogc.org", "description": "Society of Obstetricians Canada", "recherche": "https://www.sogc.org/en/content/search.aspx?q="}
    },
    "Obst√©trique": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "CNGOF Obst√©trique", "recherche": "http://www.cngof.fr/?s="},
        "ACOG": {"url": "https://www.acog.org", "description": "ACOG", "recherche": "https://www.acog.org/search?q="},
        "WHO": {"url": "https://www.who.int/health-topics/maternal-health", "description": "OMS Sant√© maternelle", "recherche": "https://www.who.int/search?query="}
    },
    "Anesth√©sie-R√©animation": {
        "SFAR": {"url": "https://sfar.org", "description": "Soci√©t√© Fran√ßaise Anesth√©sie R√©animation", "recherche": "https://sfar.org/?s="},
        "ASA": {"url": "https://www.asahq.org", "description": "American Society of Anesthesiologists", "recherche": "https://www.asahq.org/search?q="},
        "ESA": {"url": "https://www.esaic.org", "description": "European Society Anaesthesiology", "recherche": "https://www.esaic.org/search?q="}
    },
    "Endocrinologie": {
        "SFE": {"url": "https://www.sfendocrino.org", "description": "Soci√©t√© Fran√ßaise Endocrinologie", "recherche": "https://www.sfendocrino.org/?s="},
        "ADA": {"url": "https://diabetes.org", "description": "American Diabetes Association", "recherche": "https://diabetes.org/search?q="},
        "EASD": {"url": "https://www.easd.org", "description": "European Association Diabetes", "recherche": "https://www.easd.org/search?q="}
    },
    "M√©decine G√©n√©rale": {
        "HAS": {"url": "https://www.has-sante.fr", "description": "HAS", "recherche": "https://www.has-sante.fr/jcms/recherche?text="},
        "CNGE": {"url": "https://www.cnge.fr", "description": "Coll√®ge National G√©n√©ralistes", "recherche": "https://www.cnge.fr/?s="},
        "NICE": {"url": "https://www.nice.org.uk", "description": "NICE UK", "recherche": "https://www.nice.org.uk/search?q="}
    },
    "Chirurgie Gyn√©cologique": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "CNGOF Chirurgie", "recherche": "http://www.cngof.fr/?s="},
        "AAGL": {"url": "https://www.aagl.org", "description": "Association Gynecologic Laparoscopy", "recherche": "https://www.aagl.org/search?q="}
    },
    "Infertilit√©": {
        "ESHRE": {"url": "https://www.eshre.eu", "description": "European Society Human Reproduction", "recherche": "https://www.eshre.eu/search?q="},
        "ASRM": {"url": "https://www.asrm.org", "description": "American Society Reproductive Medicine", "recherche": "https://www.asrm.org/search?q="}
    },
    "√âchographie Gyn√©cologique": {
        "ISUOG": {"url": "https://www.isuog.org", "description": "International Society Ultrasound", "recherche": "https://www.isuog.org/search.html?q="},
        "CFEF": {"url": "http://www.cfef.org", "description": "Coll√®ge Fran√ßais √âchographie F≈ìtale", "recherche": "http://www.cfef.org/?s="}
    },
    "Oncologie": {
        "INCa": {"url": "https://www.e-cancer.fr", "description": "Institut National Cancer", "recherche": "https://www.e-cancer.fr/Recherche?SearchText="},
        "NCCN": {"url": "https://www.nccn.org", "description": "National Comprehensive Cancer Network", "recherche": "https://www.nccn.org/search?q="},
        "ESMO": {"url": "https://www.esmo.org", "description": "European Society Medical Oncology", "recherche": "https://www.esmo.org/search?q="}
    },
    "P√©diatrie": {
        "SFP": {"url": "https://www.sfpediatrie.com", "description": "Soci√©t√© Fran√ßaise P√©diatrie", "recherche": "https://www.sfpediatrie.com/?s="},
        "AAP": {"url": "https://www.aap.org", "description": "American Academy Pediatrics", "recherche": "https://www.aap.org/search?q="}
    }
}

if 'historique' not in st.session_state:
    st.session_state.historique = []
if 'articles_previsualises' not in st.session_state:
    st.session_state.articles_previsualises = []
if 'mode_etape' not in st.session_state:
    st.session_state.mode_etape = 1
if 'info_recherche' not in st.session_state:
    st.session_state.info_recherche = {}
if 'analyses_individuelles' not in st.session_state:
    st.session_state.analyses_individuelles = {}
if 'fichiers_finaux' not in st.session_state:
    st.session_state.fichiers_finaux = {}

def nettoyer_titre_complet(titre):
    if not titre:
        return "Titre non disponible"
    titre = re.sub(r'<[^>]+>', '', titre)
    titre = re.sub(r'see\s+more', '', titre, flags=re.IGNORECASE)
    titre = re.sub(r'\[see\s+more\]', '', titre, flags=re.IGNORECASE)
    titre = re.sub(r'\s+', ' ', titre)
    return titre.strip()

def traduire_texte(texte, mode="gemini"):
    if not texte or len(texte.strip()) < 3:
        return texte
    
    try:
        genai.configure(api_key=G_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        prompt = f"""Traduis en fran√ßais. UNE SEULE traduction.

{texte}"""
        
        response = model.generate_content(prompt)
        traduction = response.text.strip()
        traduction = traduction.replace("**", "").replace("Traduction:", "")
        traduction = re.sub(r'^\d+[\.\)]\s*', '', traduction)
        return nettoyer_titre_complet(traduction)
    except:
        return texte

def get_pdf_link_ameliore(pmid):
    try:
        base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi"
        params = {"dbfrom": "pubmed", "db": "pmc", "id": pmid, "retmode": "xml"}
        response = requests.get(base_url, params=params, timeout=10)
        
        urls = []
        pmc_id = None
        
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            pmc_elem = root.find('.//Link/Id')
            if pmc_elem is not None:
                pmc_id = pmc_elem.text
                urls.extend([
                    f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/pdf/",
                    f"https://europepmc.org/articles/PMC{pmc_id}?pdf=render"
                ])
        return urls, pmc_id
    except:
        return None, None

def telecharger_et_extraire_pdf(pmid, mode_traduction="gemini", progress_callback=None):
    try:
        urls, pmc_id = get_pdf_link_ameliore(pmid)
        if not urls:
            return None, "PDF non disponible"
        
        if progress_callback:
            progress_callback(f"üì• T√©l√©chargement {pmid}...")
        
        pdf_content = None
        headers_list = [
            {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0', 'Accept': 'application/pdf'},
            {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)', 'Accept': 'application/pdf'}
        ]
        
        for url in urls:
            for headers in headers_list:
                try:
                    resp = requests.get(url, timeout=30, allow_redirects=True, headers=headers)
                    if resp.status_code == 200 and (b'%PDF' in resp.content[:4] or 'pdf' in resp.headers.get('Content-Type', '')):
                        pdf_content = resp.content
                        break
                except:
                    continue
            if pdf_content:
                break
            time.sleep(0.5)
        
        if not pdf_content:
            return None, f"PDF non accessible"
        
        if progress_callback:
            progress_callback("üìÑ Extraction...")
        
        try:
            pdf_file = BytesIO(pdf_content)
            pdf_reader = pypdf.PdfReader(pdf_file)
            texte = ""
            for i in range(min(len(pdf_reader.pages), 15)):
                try:
                    texte += pdf_reader.pages[i].extract_text() + "\n\n"
                except:
                    continue
            
            if len(texte) < 100:
                return None, "Contenu insuffisant"
            
            if len(texte) > 12000:
                texte = texte[:12000]
            
            if progress_callback:
                progress_callback("üåê Traduction...")
            
            texte_trad = ""
            for i in range(0, len(texte), 4000):
                texte_trad += traduire_texte(texte[i:i+4000], mode=mode_traduction) + "\n\n"
            
            return texte_trad, None
        except Exception as e:
            return None, f"Erreur: {str(e)}"
    except:
        return None, "Erreur"

def traduire_mots_cles(mots):
    try:
        genai.configure(api_key=G_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(f"Traduis en anglais m√©dical: {mots}")
        return response.text.strip()
    except:
        return mots

def recuperer_titres_rapides(pmids, traduire_titres=False, mode_traduction="gemini"):
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    params = {"db": "pubmed", "id": ",".join(pmids), "retmode": "xml"}
    
    try:
        response = requests.get(base_url, params=params, timeout=15)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            articles = []
            
            for article in root.findall('.//PubmedArticle'):
                pmid = article.find('.//PMID').text if article.find('.//PMID') is not None else "N/A"
                
                title_elem = article.find('.//ArticleTitle')
                title = ''.join(title_elem.itertext()) if title_elem is not None else "Titre non disponible"
                title = nettoyer_titre_complet(title)
                
                if traduire_titres and title != "Titre non disponible":
                    title_fr = traduire_texte(title, mode=mode_traduction)
                    title_fr = nettoyer_titre_complet(title_fr)
                else:
                    title_fr = title
                
                journal_elem = article.find('.//Journal/Title')
                journal = journal_elem.text if journal_elem is not None else "N/A"
                
                year = article.find('.//PubDate/Year')
                year = year.text if year is not None else "N/A"
                
                articles.append({
                    'pmid': pmid,
                    'title': title,
                    'title_fr': title_fr,
                    'journal': journal,
                    'year': year,
                    'date_pub': year
                })
            
            return articles
    except:
        return []
    return []

class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, 'Veille Medicale', 0, 1, 'C')
        self.ln(5)
    
    def footer(self):
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')

def generer_pdf_selectionne(spec, periode, articles):
    pdf = PDF()
    pdf.add_page()
    pdf.set_font('Arial', 'B', 20)
    pdf.cell(0, 15, 'VEILLE MEDICALE', 0, 1, 'C')
    pdf.ln(10)
    pdf.set_font('Arial', '', 12)
    pdf.cell(0, 8, f'Specialite: {spec}', 0, 1, 'C')
    pdf.cell(0, 8, f'Periode: {periode}', 0, 1, 'C')
    
    for i, article in enumerate(articles, 1):
        pdf.add_page()
        pdf.set_font('Arial', 'B', 14)
        pdf.cell(0, 10, f'Article {i} - PMID {article["pmid"]}', 0, 1)
        pdf.set_font('Arial', '', 10)
        try:
            title = article['title_fr'].encode('latin-1', 'ignore').decode('latin-1')
        except:
            title = article['title_fr'].encode('ascii', 'ignore').decode('ascii')
        pdf.multi_cell(0, 5, title)
    
    output = io.BytesIO()
    pdf_string = pdf.output(dest='S').encode('latin-1')
    output.write(pdf_string)
    output.seek(0)
    return output.getvalue()

def generer_notebooklm_selectionne(articles):
    contenu = f"""# VEILLE MEDICALE
Date: {datetime.now().strftime("%d/%m/%Y")}

"""
    for i, article in enumerate(articles, 1):
        contenu += f"""
### Article {i}
Titre: {article['title_fr']}
Journal: {article['journal']}
PMID: {article['pmid']}

{article.get('pdf_texte_fr', '')}

---
"""
    return contenu

st.title("ü©∫ Veille M√©dicale Professionnelle")

if DEEPL_KEY:
    st.success("‚úÖ DeepL Pro+ activ√©")
else:
    st.info("‚ÑπÔ∏è Gemini 2.0 Flash")

tab1, tab2, tab3 = st.tabs(["üîç Recherche", "üîó Sources", "‚öôÔ∏è Config"])

with tab1:
    if st.session_state.mode_etape == 1:
        st.header("üìã √âtape 1 : Pr√©visualisation")
        
        with st.sidebar:
            st.header("‚öôÔ∏è Param√®tres")
            
            mode_recherche = st.radio("Mode", ["Par sp√©cialit√©", "Par mots-cl√©s"])
            
            if mode_recherche == "Par sp√©cialit√©":
                spec_fr = st.selectbox("üè• Sp√©cialit√©", list(TRAD.keys()))
                mots_cles_custom = ""
                
                st.subheader("üì∞ Journaux")
                choix_journaux = st.radio("Limiter √†:", ["Tous PubMed", "Journaux sp√©cialit√©", "Un journal"])
                
                if choix_journaux == "Un journal":
                    journal_selectionne = st.selectbox("Journal:", JOURNAUX_SPECIALITE.get(spec_fr, []))
                elif choix_journaux == "Journaux sp√©cialit√©":
                    journal_selectionne = "SPECIALITE"
                else:
                    journal_selectionne = "TOUS"
            else:
                spec_fr = None
                mots_cles_custom = st.text_area("üîé Mots-cl√©s", height=80)
                journal_selectionne = "TOUS"
            
            st.subheader("üìÖ P√©riode")
            col1, col2 = st.columns(2)
            with col1:
                date_debut = st.date_input("D√©but", value=date(2024, 1, 1), format="DD/MM/YYYY")
            with col2:
                date_fin = st.date_input("Fin", value=date.today(), format="DD/MM/YYYY")
            
            st.subheader("üî¨ Filtres")
            mode_contenu = st.radio("Type:", ["PDF complets uniquement", "Titre + r√©sum√©"])
            type_etude = st.selectbox("√âtude", list(TYPES_ETUDE.keys()))
            nb_max = st.slider("Max", 10, 200, 50, 10)
            
            traduire_titres = st.checkbox("üåê Traduire titres", value=True)
        
        if st.button("üîç LANCER", type="primary", use_container_width=True):
            if mode_recherche == "Par sp√©cialit√©":
                term = TRAD[spec_fr]
                display_term = spec_fr
                spec_utilisee = spec_fr
            else:
                if not mots_cles_custom:
                    st.error("‚ö†Ô∏è Entrez mots-cl√©s")
                    st.stop()
                term = traduire_mots_cles(mots_cles_custom)
                display_term = f"Mots-cl√©s: {mots_cles_custom}"
                spec_utilisee = "Personnalis√©"
            
            query_parts = [term]
            query_parts.append(f"{date_debut.strftime('%Y/%m/%d')}:{date_fin.strftime('%Y/%m/%d')}[pdat]")
            
            if "PDF complets" in mode_contenu:
                query_parts.append("free full text[sb]")
            
            if journal_selectionne == "SPECIALITE":
                journaux = JOURNAUX_SPECIALITE.get(spec_utilisee, [])
                if journaux:
                    journaux_q = " OR ".join([f'"{j}"[Journal]' for j in journaux])
                    query_parts.append(f"({journaux_q})")
            elif journal_selectionne != "TOUS":
                query_parts.append(f'"{journal_selectionne}"[Journal]')
            
            if TYPES_ETUDE[type_etude]:
                query_parts.append(f"{TYPES_ETUDE[type_etude]}[ptyp]")
            
            query = " AND ".join(query_parts)
            
            base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {"db": "pubmed", "term": query, "retmode": "json", "retmax": nb_max, "sort": "date"}
            
            try:
                with st.spinner("Recherche..."):
                    response = requests.get(base_url, params=params, timeout=15)
                
                if response.status_code != 200:
                    st.error(f"Erreur: {response.status_code}")
                    st.stop()
                
                data = response.json()
                ids = data.get("esearchresult", {}).get("idlist", [])
                count = data.get("esearchresult", {}).get("count", "0")
                
                if not ids:
                    st.warning("Aucun article")
                    st.stop()
                
                st.success(f"‚úÖ {count} articles - {len(ids)} affich√©s")
                
                with st.spinner("R√©cup√©ration..."):
                    articles_preview = recuperer_titres_rapides(ids, traduire_titres=traduire_titres)
                
                st.session_state.articles_previsualises = articles_preview
                st.session_state.info_recherche = {
                    'display_term': display_term,
                    'periode': f"du {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}",
                    'spec': spec_utilisee,
                    'mode_traduction': 'gemini'
                }
                
                st.session_state.mode_etape = 2
                st.rerun()
            except Exception as e:
                st.error(f"Erreur: {str(e)}")
    
    elif st.session_state.mode_etape == 2:
        st.header("üìë √âtape 2 : S√©lection")
        
        st.info(f"{st.session_state.info_recherche['display_term']} | {st.session_state.info_recherche['periode']}")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ Tout"):
                for i in range(len(st.session_state.articles_previsualises)):
                    st.session_state[f"select_{i}"] = True
                st.rerun()
        with col2:
            if st.button("‚Ü©Ô∏è Nouvelle"):
                st.session_state.mode_etape = 1
                st.session_state.articles_previsualises = []
                st.rerun()
        
        st.divider()
        
        articles_sel = []
        
        for i, article in enumerate(st.session_state.articles_previsualises):
            col_c, col_i = st.columns([0.1, 0.9])
            with col_c:
                selected = st.checkbox("", key=f"select_{i}", label_visibility="collapsed")
            with col_i:
                st.markdown(f"**{i+1}. {article['title_fr']}**")
                st.caption(f"üì∞ {article['journal']} | {article['year']} | PMID: {article['pmid']}")
            
            if selected:
                articles_sel.append(article['pmid'])
            st.divider()
        
        st.markdown(f"**{len(articles_sel)} s√©lectionn√©(s)**")
        
        if 0 < len(articles_sel) <= 20:
            if st.button("üöÄ ANALYSER", type="primary", use_container_width=True):
                st.session_state.analyses_individuelles = {}
                
                for idx, pmid in enumerate(articles_sel):
                    st.subheader(f"üìÑ Article {idx+1}/{len(articles_sel)} - {pmid}")
                    
                    article_info = next((a for a in st.session_state.articles_previsualises if a['pmid'] == pmid), None)
                    if not article_info:
                        continue
                    
                    st.markdown(f"**{article_info['title_fr']}**")
                    
                    status = st.empty()
                    
                    def callback(msg):
                        status.info(msg)
                    
                    pdf_texte, erreur = telecharger_et_extraire_pdf(pmid, progress_callback=callback)
                    status.empty()
                    
                    if pdf_texte:
                        st.success(f"‚úÖ PDF extrait ({len(pdf_texte)} car.)")
                        
                        with st.expander("üìÑ PDF"):
                            st.text_area("", pdf_texte, height=400, key=f"pdf_{pmid}")
                        
                        with st.spinner("ü§ñ Analyse..."):
                            try:
                                genai.configure(api_key=G_KEY)
                                model = genai.GenerativeModel('gemini-2.0-flash-exp')
                                
                                prompt = f"""Analyse m√©dicale.

Titre: {article_info['title_fr']}
Journal: {article_info['journal']}

{pdf_texte}

Analyse:
## Objectif
## M√©thodologie
## R√©sultats
## Conclusion"""
                                
                                response = model.generate_content(prompt)
                                analyse = response.text
                                
                                st.markdown("### ü§ñ Analyse")
                                st.markdown(analyse)
                                
                                st.session_state.analyses_individuelles[pmid] = {
                                    'pmid': pmid,
                                    'title_fr': article_info['title_fr'],
                                    'journal': article_info['journal'],
                                    'year': article_info['year'],
                                    'pdf_texte_fr': pdf_texte,
                                    'analyse_ia': analyse
                                }
                            except Exception as e:
                                st.error(f"Erreur: {str(e)}")
                    else:
                        st.error(f"‚ùå {erreur}")
                    
                    st.divider()
                
                if st.session_state.analyses_individuelles:
                    st.session_state.mode_etape = 3
                    st.rerun()
    
    elif st.session_state.mode_etape == 3:
        st.header("üìö √âtape 3 : S√©lection finale")
        
        articles_finaux_ids = []
        
        for pmid, data in st.session_state.analyses_individuelles.items():
            col_c, col_i = st.columns([0.1, 0.9])
            with col_c:
                include = st.checkbox("", key=f"final_{pmid}", value=True, label_visibility="collapsed")
            with col_i:
                st.markdown(f"**{data['title_fr']}**")
                st.caption(f"{data['journal']} | {data['year']}")
                with st.expander("ü§ñ Analyse"):
                    st.markdown(data['analyse_ia'])
            
            if include:
                articles_finaux_ids.append(pmid)
            st.divider()
        
        if articles_finaux_ids:
            st.success(f"‚úÖ {len(articles_finaux_ids)} s√©lectionn√©(s)")
            
            if st.button("üì¶ G√âN√âRER", type="primary", use_container_width=True):
                articles_finaux = [st.session_state.analyses_individuelles[pmid] for pmid in articles_finaux_ids]
                
                with st.spinner("G√©n√©ration..."):
                    pdf_final = generer_pdf_selectionne(
                        st.session_state.info_recherche['spec'],
                        st.session_state.info_recherche['periode'],
                        articles_finaux
                    )
                    notebooklm = generer_notebooklm_selectionne(articles_finaux)
                
                st.session_state.fichiers_finaux = {
                    'pdf': pdf_final,
                    'notebooklm': notebooklm,
                    'articles': articles_finaux
                }
                
                st.session_state.mode_etape = 4
                st.rerun()
    
    elif st.session_state.mode_etape == 4:
        st.header("üéâ Termin√©!")
        
        st.success(f"‚úÖ {len(st.session_state.fichiers_finaux['articles'])} article(s)")
        
        st.subheader("üì• T√©l√©chargements")
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "üìÑ PDF",
                st.session_state.fichiers_finaux['pdf'],
                f"veille_{datetime.now().strftime('%Y%m%d')}.pdf",
                mime="application/pdf",
                use_container_width=True
            )
        with col2:
            st.download_button(
                "üéôÔ∏è NotebookLM",
                st.session_state.fichiers_finaux['notebooklm'],
                f"podcast_{datetime.now().strftime('%Y%m%d')}.txt",
                use_container_width=True
            )
        
        st.link_button("üîó NotebookLM", "https://notebooklm.google.com", use_container_width=True)
        
        if st.button("üîÑ Nouvelle", use_container_width=True):
            st.session_state.mode_etape = 1
            st.session_state.articles_previsualises = []
            st.session_state.analyses_individuelles = {}
            st.session_state.fichiers_finaux = {}
            st.rerun()

with tab2:
    st.header("üîó Sources")
    
    spec_src = st.selectbox("Sp√©cialit√©:", list(SOURCES_PAR_SPECIALITE.keys()))
    
    for nom, info in SOURCES_PAR_SPECIALITE[spec_src].items():
        with st.expander(f"üìö {nom}"):
            st.markdown(f"**{info['description']}**")
            mots = st.text_input("Rechercher:", key=f"src_{nom}")
            col1, col2 = st.columns(2)
            with col1:
                if mots:
                    st.link_button("üîç", f"{info['recherche']}{mots}")
            with col2:
                st.link_button("üè†", info['url'])

with tab3:
    st.header("‚öôÔ∏è Config")
    st.info("DeepL Pro+ : 29,99‚Ç¨/mois")

st.caption("üíä Gemini 2.0 Flash")
