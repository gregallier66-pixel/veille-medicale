import streamlit as st
import google.generativeai as genai
import requests
from datetime import datetime, date
import xml.etree.ElementTree as ET
from fpdf import FPDF
import io
import pypdf
from io import BytesIO
import re
import time

st.set_page_config(page_title="Veille M√©dicale Pro", layout="wide")

try:
    G_KEY = st.secrets["GEMINI_KEY"]
except:
    st.error("‚ö†Ô∏è Cl√© GEMINI_KEY manquante")
    st.stop()

DEEPL_KEY = st.secrets.get("DEEPL_KEY", None)

TRAD = {
    "Gyn√©cologie": "Gynecology",
    "Obst√©trique": "Obstetrics",
    "Anesth√©sie-R√©animation": "Anesthesiology",
    "Endocrinologie": "Endocrinology",
    "M√©decine G√©n√©rale": "General Medicine",
    "Chirurgie Gyn√©cologique": "Gynecologic Surgery",
    "Infertilit√©": "Infertility",
    "√âchographie Gyn√©cologique": "Gynecologic Ultrasound",
    "Oncologie": "Oncology",
    "P√©diatrie": "Pediatrics"
}

TYPES_ETUDE = {
    "Tous": "",
    "Essais cliniques": "Clinical Trial",
    "M√©ta-analyses": "Meta-Analysis",
    "Revues syst√©matiques": "Systematic Review",
    "√âtudes de cohorte": "Cohort Studies",
    "√âtudes cas-t√©moins": "Case-Control Studies"
}

JOURNAUX_SPECIALITE = {
    "Gyn√©cologie": ["BJOG", "Obstet Gynecol", "Am J Obstet Gynecol", "Hum Reprod", "Fertil Steril"],
    "Obst√©trique": ["BJOG", "Obstet Gynecol", "Am J Obstet Gynecol", "Ultrasound Obstet Gynecol"],
    "Anesth√©sie-R√©animation": ["Anesthesiology", "Br J Anaesth", "Anesth Analg"],
    "Endocrinologie": ["J Clin Endocrinol Metab", "Diabetes Care", "Eur J Endocrinol"],
    "M√©decine G√©n√©rale": ["BMJ", "JAMA", "N Engl J Med", "Lancet"],
    "Chirurgie Gyn√©cologique": ["Gynecol Surg", "J Minim Invasive Gynecol"],
    "Infertilit√©": ["Fertil Steril", "Hum Reprod"],
    "√âchographie Gyn√©cologique": ["Ultrasound Obstet Gynecol", "J Ultrasound Med"],
    "Oncologie": ["J Clin Oncol", "Lancet Oncol", "Cancer"],
    "P√©diatrie": ["Pediatrics", "JAMA Pediatr"]
}

SOURCES_PAR_SPECIALITE = {
    "Gyn√©cologie": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "Coll√®ge National Gyn√©cologues Obst√©triciens", "recherche": "http://www.cngof.fr/?s="},
        "ACOG": {"url": "https://www.acog.org", "description": "American College Obstetricians Gynecologists", "recherche": "https://www.acog.org/search?q="},
        "RCOG": {"url": "https://www.rcog.org.uk", "description": "Royal College UK", "recherche": "https://www.rcog.org.uk/search?q="},
        "HAS": {"url": "https://www.has-sante.fr", "description": "Haute Autorit√© Sant√©", "recherche": "https://www.has-sante.fr/jcms/recherche?text="},
        "SOGC": {"url": "https://www.sogc.org", "description": "Society Obstetricians Canada", "recherche": "https://www.sogc.org/en/content/search.aspx?q="}
    },
    "Obst√©trique": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "CNGOF", "recherche": "http://www.cngof.fr/?s="},
        "ACOG": {"url": "https://www.acog.org", "description": "ACOG", "recherche": "https://www.acog.org/search?q="},
        "WHO": {"url": "https://www.who.int/health-topics/maternal-health", "description": "OMS Sant√© maternelle", "recherche": "https://www.who.int/search?query="},
        "FIGO": {"url": "https://www.figo.org", "description": "FIGO", "recherche": "https://www.figo.org/?s="}
    },
    "Anesth√©sie-R√©animation": {
        "SFAR": {"url": "https://sfar.org", "description": "SFAR", "recherche": "https://sfar.org/?s="},
        "ASA": {"url": "https://www.asahq.org", "description": "ASA", "recherche": "https://www.asahq.org/search?q="},
        "ESA": {"url": "https://www.esaic.org", "description": "ESA", "recherche": "https://www.esaic.org/search?q="}
    },
    "Endocrinologie": {
        "SFE": {"url": "https://www.sfendocrino.org", "description": "SFE", "recherche": "https://www.sfendocrino.org/?s="},
        "ADA": {"url": "https://diabetes.org", "description": "ADA", "recherche": "https://diabetes.org/search?q="},
        "EASD": {"url": "https://www.easd.org", "description": "EASD", "recherche": "https://www.easd.org/search?q="}
    },
    "M√©decine G√©n√©rale": {
        "HAS": {"url": "https://www.has-sante.fr", "description": "HAS", "recherche": "https://www.has-sante.fr/jcms/recherche?text="},
        "CNGE": {"url": "https://www.cnge.fr", "description": "CNGE", "recherche": "https://www.cnge.fr/?s="},
        "NICE": {"url": "https://www.nice.org.uk", "description": "NICE", "recherche": "https://www.nice.org.uk/search?q="}
    },
    "Chirurgie Gyn√©cologique": {
        "CNGOF": {"url": "http://www.cngof.fr", "description": "CNGOF", "recherche": "http://www.cngof.fr/?s="},
        "AAGL": {"url": "https://www.aagl.org", "description": "AAGL", "recherche": "https://www.aagl.org/search?q="}
    },
    "Infertilit√©": {
        "ESHRE": {"url": "https://www.eshre.eu", "description": "ESHRE", "recherche": "https://www.eshre.eu/search?q="},
        "ASRM": {"url": "https://www.asrm.org", "description": "ASRM", "recherche": "https://www.asrm.org/search?q="}
    },
    "√âchographie Gyn√©cologique": {
        "ISUOG": {"url": "https://www.isuog.org", "description": "ISUOG", "recherche": "https://www.isuog.org/search.html?q="},
        "CFEF": {"url": "http://www.cfef.org", "description": "CFEF", "recherche": "http://www.cfef.org/?s="}
    },
    "Oncologie": {
        "INCa": {"url": "https://www.e-cancer.fr", "description": "INCa", "recherche": "https://www.e-cancer.fr/Recherche?SearchText="},
        "NCCN": {"url": "https://www.nccn.org", "description": "NCCN", "recherche": "https://www.nccn.org/search?q="},
        "ESMO": {"url": "https://www.esmo.org", "description": "ESMO", "recherche": "https://www.esmo.org/search?q="}
    },
    "P√©diatrie": {
        "SFP": {"url": "https://www.sfpediatrie.com", "description": "SFP", "recherche": "https://www.sfpediatrie.com/?s="},
        "AAP": {"url": "https://www.aap.org", "description": "AAP", "recherche": "https://www.aap.org/search?q="}
    }
}

if 'historique' not in st.session_state:
    st.session_state.historique = []
if 'articles_previsualises' not in st.session_state:
    st.session_state.articles_previsualises = []
if 'mode_etape' not in st.session_state:
    st.session_state.mode_etape = 1
if 'info_recherche' not in st.session_state:
    st.session_state.info_recherche = {}
if 'analyses_individuelles' not in st.session_state:
    st.session_state.analyses_individuelles = {}
if 'fichiers_finaux' not in st.session_state:
    st.session_state.fichiers_finaux = {}

def nettoyer_titre_complet(titre):
    if not titre:
        return "Titre non disponible"
    titre = re.sub(r'<[^>]+>', '', titre)
    titre = re.sub(r'see\s+more', '', titre, flags=re.IGNORECASE)
    titre = re.sub(r'\[see\s+more\]', '', titre, flags=re.IGNORECASE)
    titre = re.sub(r'\s+', ' ', titre)
    return titre.strip()

def traduire_texte(texte, mode="gemini"):
    if not texte or len(texte.strip()) < 3:
        return texte
    
    try:
        genai.configure(api_key=G_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        prompt = f"""Traduis en fran√ßais professionnel. UNE SEULE traduction.

{texte}"""
        
        response = model.generate_content(prompt)
        traduction = response.text.strip()
        traduction = traduction.replace("**", "").replace("Traduction:", "")
        traduction = re.sub(r'^\d+[\.\)]\s*', '', traduction)
        return nettoyer_titre_complet(traduction)
    except:
        return texte

def obtenir_tous_liens_pdf(pmid):
    """Obtient TOUS les liens PDF possibles incluant DOI et liens externes"""
    try:
        urls = []
        pmc_id = None
        doi = None
        
        # 1. R√©cup√©rer les m√©tadonn√©es compl√®tes
        fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
        fetch_params = {"db": "pubmed", "id": pmid, "retmode": "xml"}
        
        try:
            response = requests.get(fetch_url, params=fetch_params, timeout=10)
            if response.status_code == 200:
                root = ET.fromstring(response.content)
                
                # PMC ID
                pmc_elem = root.find('.//ArticleId[@IdType="pmc"]')
                if pmc_elem is not None:
                    pmc_id = pmc_elem.text.replace("PMC", "")
                
                # DOI
                doi_elem = root.find('.//ArticleId[@IdType="doi"]')
                if doi_elem is not None:
                    doi = doi_elem.text
        except:
            pass
        
        # 2. Si PMC ID trouv√©, ajouter URLs PMC
        if pmc_id:
            urls.extend([
                f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/pdf/",
                f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/pdf/main.pdf",
                f"https://europepmc.org/articles/PMC{pmc_id}?pdf=render",
                f"https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC{pmc_id}&blobtype=pdf"
            ])
        
        # 3. Si DOI trouv√©, ajouter liens √©diteurs
        if doi:
            # DOI direct
            urls.append(f"https://doi.org/{doi}")
            
            # Unpaywall (acc√®s ouvert)
            urls.append(f"https://api.unpaywall.org/v2/{doi}?email=research@example.com")
        
        # 4. eLink vers PMC (backup)
        try:
            elink_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi"
            elink_params = {"dbfrom": "pubmed", "db": "pmc", "id": pmid, "retmode": "xml"}
            elink_response = requests.get(elink_url, params=elink_params, timeout=10)
            
            if elink_response.status_code == 200:
                elink_root = ET.fromstring(elink_response.content)
                elink_pmc = elink_root.find('.//Link/Id')
                if elink_pmc is not None and not pmc_id:
                    pmc_id = elink_pmc.text
                    urls.extend([
                        f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmc_id}/pdf/",
                        f"https://europepmc.org/articles/PMC{pmc_id}?pdf=render"
                    ])
        except:
            pass
        
        return urls, pmc_id, doi
        
    except Exception as e:
        return [], None, None

def telecharger_et_extraire_pdf(pmid, mode_traduction="gemini", progress_callback=None):
    """Version ULTRA optimis√©e avec unpaywall et multiples sources"""
    try:
        urls_possibles, pmc_id, doi = obtenir_tous_liens_pdf(pmid)
        
        if not urls_possibles:
            return None, "PDF non disponible en libre acc√®s"
        
        if progress_callback:
            progress_callback(f"üì• Recherche PDF PMID {pmid}...")
        
        pdf_content = None
        url_reussie = None
        
        # User-Agents vari√©s
        headers_list = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/pdf,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            },
            {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
                'Accept': 'application/pdf'
            },
            {
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0',
                'Accept': 'application/pdf,text/html'
            }
        ]
        
        # Essayer CHAQUE URL avec CHAQUE header
        for url in urls_possibles:
            if pdf_content:
                break
            
            # Cas sp√©cial : Unpaywall API
            if 'unpaywall.org' in url:
                try:
                    resp = requests.get(url, timeout=15)
                    if resp.status_code == 200:
                        data = resp.json()
                        if data.get('is_oa') and data.get('best_oa_location'):
                            pdf_url = data['best_oa_location'].get('url_for_pdf')
                            if pdf_url:
                                urls_possibles.insert(0, pdf_url)
                except:
                    pass
                continue
            
            for headers in headers_list:
                try:
                    response = requests.get(
                        url,
                        timeout=30,
                        allow_redirects=True,
                        headers=headers,
                        stream=True
                    )
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('Content-Type', '').lower()
                        
                        # Lire le d√©but du contenu
                        content_preview = response.content[:20]
                        
                        # V√©rifier si c'est un PDF
                        is_pdf = (
                            b'%PDF' in content_preview or
                            'application/pdf' in content_type or
                            'pdf' in content_type
                        )
                        
                        if is_pdf:
                            pdf_content = response.content
                            url_reussie = url
                            if progress_callback:
                                progress_callback(f"‚úÖ PDF trouv√© ({len(pdf_content)} bytes)")
                            break
                
                except Exception as e:
                    continue
                
                time.sleep(0.2)
        
        if not pdf_content:
            msg_erreur = "PDF non accessible"
            if pmc_id:
                msg_erreur += f" (PMC{pmc_id})"
            if doi:
                msg_erreur += f" - DOI: {doi}"
            msg_erreur += ". Abonnement institutionnel peut √™tre n√©cessaire."
            return None, msg_erreur
        
        if progress_callback:
            progress_callback(f"üìÑ Extraction texte...")
        
        try:
            pdf_file = BytesIO(pdf_content)
            pdf_reader = pypdf.PdfReader(pdf_file)
            
            texte_complet = ""
            nb_pages = len(pdf_reader.pages)
            max_pages = min(nb_pages, 15)
            
            for i in range(max_pages):
                try:
                    texte_page = pdf_reader.pages[i].extract_text()
                    if texte_page:
                        texte_complet += texte_page + "\n\n"
                except:
                    continue
            
            if len(texte_complet) < 100:
                return None, "Contenu PDF insuffisant"
            
            if len(texte_complet) > 12000:
                texte_complet = texte_complet[:12000] + "\n\n[Tronqu√©]"
            
            if progress_callback:
                progress_callback(f"üåê Traduction...")
            
            # Traduction
            chunk_size = 4000
            texte_traduit = ""
            
            for i in range(0, len(texte_complet), chunk_size):
                chunk = texte_complet[i:i+chunk_size]
                trad = traduire_texte(chunk, mode=mode_traduction)
                texte_traduit += trad + "\n\n"
                
                if progress_callback and i > 0:
                    pct = min(100, int((i/len(texte_complet))*100))
                    progress_callback(f"üåê Traduction {pct}%...")
            
            return texte_traduit, None
            
        except Exception as e:
            return None, f"Erreur extraction: {str(e)}"
            
    except Exception as e:
        return None, f"Erreur: {str(e)}"

def traduire_mots_cles(mots):
    """Traduit les mots-cl√©s fran√ßais en termes m√©dicaux anglais"""
    try:
        genai.configure(api_key=G_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        prompt = f"""Traduis ces termes m√©dicaux fran√ßais en anglais m√©dical standard pour PubMed.

R√àGLES:
- Utilise la terminologie MeSH (Medical Subject Headings)
- Donne UNIQUEMENT les termes anglais, sans explication
- Pas de guillemets, pas de ponctuation superflue
- Variantes orthographiques accept√©es

Exemples:
dysm√©norrh√©e ‚Üí dysmenorrhea
hypertension gravidique ‚Üí gestational hypertension
pr√©-√©clampsie ‚Üí preeclampsia

Termes √† traduire: {mots}

Traduction:"""
        
        response = model.generate_content(prompt)
        traduction = response.text.strip()
        
        # Nettoyer
        traduction = traduction.replace('"', '').replace("'", "")
        traduction = traduction.replace("‚Üí", "").replace(":", "")
        traduction = traduction.strip()
        
        return traduction
    except Exception as e:
        # Fallback : retourner tel quel
        return mots

def recuperer_titres_rapides(pmids, traduire_titres=False, mode_traduction="gemini"):
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    params = {"db": "pubmed", "id": ",".join(pmids), "retmode": "xml"}
    
    try:
        response = requests.get(base_url, params=params, timeout=15)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            articles = []
            
            for article in root.findall('.//PubmedArticle'):
                pmid = article.find('.//PMID').text if article.find('.//PMID') is not None else "N/A"
                
                title_elem = article.find('.//ArticleTitle')
                title = ''.join(title_elem.itertext()) if title_elem is not None else "Titre non disponible"
                title = nettoyer_titre_complet(title)
                
                if traduire_titres and title != "Titre non disponible":
                    title_fr = traduire_texte(title, mode=mode_traduction)
                    title_fr = nettoyer_titre_complet(title_fr)
                else:
                    title_fr = title
                
                journal_elem = article.find('.//Journal/Title')
                journal = journal_elem.text if journal_elem is not None else "N/A"
                
                year = article.find('.//PubDate/Year')
                year = year.text if year is not None else "N/A"
                
                month = article.find('.//PubDate/Month')
                month = month.text if month is not None else ""
                
                day = article.find('.//PubDate/Day')
                day = day.text if day is not None else ""
                
                if month and day:
                    date_pub = f"{day}/{month}/{year}"
                elif month:
                    date_pub = f"{month} {year}"
                else:
                    date_pub = year
                
                articles.append({
                    'pmid': pmid,
                    'title': title,
                    'title_fr': title_fr,
                    'journal': journal,
                    'year': year,
                    'date_pub': date_pub
                })
            
            return articles
    except:
        return []
    return []

class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, 'Veille Medicale', 0, 1, 'C')
        self.ln(5)
    
    def footer(self):
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')

def generer_pdf_selectionne(spec, periode, articles):
    pdf = PDF()
    pdf.add_page()
    pdf.set_font('Arial', 'B', 20)
    pdf.cell(0, 15, 'VEILLE MEDICALE', 0, 1, 'C')
    pdf.ln(10)
    pdf.set_font('Arial', '', 12)
    pdf.cell(0, 8, f'Specialite: {spec}', 0, 1, 'C')
    pdf.cell(0, 8, f'Periode: {periode}', 0, 1, 'C')
    
    for i, article in enumerate(articles, 1):
        pdf.add_page()
        pdf.set_font('Arial', 'B', 14)
        pdf.cell(0, 10, f'Article {i} - PMID {article["pmid"]}', 0, 1)
        pdf.set_font('Arial', '', 10)
        try:
            title = article['title_fr'].encode('latin-1', 'ignore').decode('latin-1')
        except:
            title = article['title_fr'].encode('ascii', 'ignore').decode('ascii')
        pdf.multi_cell(0, 5, title)
        pdf.ln(2)
        pdf.cell(0, 5, f"{article['journal']} - {article['year']}", 0, 1)
    
    output = io.BytesIO()
    pdf_string = pdf.output(dest='S').encode('latin-1')
    output.write(pdf_string)
    output.seek(0)
    return output.getvalue()

def generer_notebooklm_selectionne(articles):
    contenu = f"""# VEILLE MEDICALE - PODCAST
Date: {datetime.now().strftime("%d/%m/%Y")}

"""
    for i, article in enumerate(articles, 1):
        contenu += f"""
### Article {i}
Titre: {article['title_fr']}
Journal: {article['journal']} ({article['year']})
PMID: {article['pmid']}

Contenu:
{article.get('pdf_texte_fr', 'Non disponible')}

---
"""
    return contenu

st.title("ü©∫ Veille M√©dicale Professionnelle")

if DEEPL_KEY:
    st.success("‚úÖ DeepL Pro+ activ√©")
else:
    st.info("‚ÑπÔ∏è Gemini 2.0 Flash")

tab1, tab2, tab3 = st.tabs(["üîç Recherche", "üîó Sources", "‚öôÔ∏è Config"])

with tab1:
    if st.session_state.mode_etape == 1:
        st.header("üìã √âtape 1 : Pr√©visualisation")
        
        with st.sidebar:
            st.header("‚öôÔ∏è Param√®tres")
            
            mode_recherche = st.radio("Mode de recherche", ["Par sp√©cialit√©", "Par mots-cl√©s"])
            
            # CORRECTION : Options compl√®tes pour les DEUX modes
            if mode_recherche == "Par sp√©cialit√©":
                spec_fr = st.selectbox("üè• Sp√©cialit√©", list(TRAD.keys()))
                mots_cles_custom = ""
                spec_combo = None
                
                st.subheader("üì∞ Journaux")
                choix_journaux = st.radio(
                    "Limiter la recherche √†:",
                    ["Tous les journaux PubMed", "Journaux de la sp√©cialit√© uniquement", "Un journal sp√©cifique"]
                )
                
                if choix_journaux == "Un journal sp√©cifique":
                    journaux_dispo = JOURNAUX_SPECIALITE.get(spec_fr, [])
                    journal_selectionne = st.selectbox("Choisir le journal:", journaux_dispo)
                elif choix_journaux == "Journaux de la sp√©cialit√© uniquement":
                    journal_selectionne = "SPECIALITE"
                else:
                    journal_selectionne = "TOUS"
                    
            else:  # Par mots-cl√©s
                spec_fr = None
                mots_cles_custom = st.text_area("üîé Mots-cl√©s", placeholder="Ex: hypertension gravidique", height=80)
                
                # AJOUT : Choix sp√©cialit√© optionnel pour mots-cl√©s
                inclure_specialite = st.checkbox("üî¨ Cibler une sp√©cialit√©", value=False)
                
                if inclure_specialite:
                    spec_combo = st.selectbox("Sp√©cialit√©:", list(TRAD.keys()))
                    
                    st.subheader("üì∞ Journaux")
                    choix_journaux = st.radio(
                        "Limiter la recherche √†:",
                        ["Tous les journaux PubMed",
                         "Journaux de la sp√©cialit√© uniquement",
                         "Un journal sp√©cifique"]
                    )
                    
                    if choix_journaux == "Un journal sp√©cifique":
                        journaux_dispo = JOURNAUX_SPECIALITE.get(spec_combo, [])
                        journal_selectionne = st.selectbox("Choisir le journal:", journaux_dispo)
                    elif choix_journaux == "Journaux de la sp√©cialit√© uniquement":
                        journal_selectionne = "SPECIALITE"
                    else:
                        journal_selectionne = "TOUS"
                else:
                    spec_combo = None
                    journal_selectionne = "TOUS"
                    st.info("üåê Recherche dans TOUS les journaux PubMed (30 000+ revues)")
            
            st.subheader("üìÖ P√©riode")
            col1, col2 = st.columns(2)
            with col1:
                st.write("**D√©but**")
                date_debut = st.date_input("D√©but", value=date(2024, 1, 1), format="DD/MM/YYYY", label_visibility="collapsed")
            with col2:
                st.write("**Fin**")
                date_fin = st.date_input("Fin", value=date.today(), format="DD/MM/YYYY", label_visibility="collapsed")
            
            st.subheader("üî¨ Filtres")
            mode_contenu = st.radio("Type de contenu:", ["PDF complets uniquement", "Titre + r√©sum√©"])
            type_etude = st.selectbox("Type d'√©tude", list(TYPES_ETUDE.keys()))
            nb_max = st.slider("Nombre max de r√©sultats", 10, 200, 50, 10)
            
            traduire_titres = st.checkbox("üåê Traduire les titres en fran√ßais", value=True)
        
        if st.button("üîç LANCER LA RECHERCHE", type="primary", use_container_width=True):
            
            # Construction requ√™te
            if mode_recherche == "Par sp√©cialit√©":
                term = TRAD[spec_fr]
                display_term = spec_fr
                spec_utilisee = spec_fr
            else:
                if not mots_cles_custom:
                    st.error("‚ö†Ô∏è Veuillez entrer des mots-cl√©s")
                    st.stop()
                
                with st.spinner("üåê Traduction des mots-cl√©s..."):
                    term = traduire_mots_cles(mots_cles_custom)
                
                # AFFICHER la traduction
                with st.expander("üîç Aper√ßu traduction"):
                    st.markdown(f"**Fran√ßais:** {mots_cles_custom}")
                    st.markdown(f"**Anglais (PubMed):** `{term}`")
                
                display_term = f"Mots-cl√©s: {mots_cles_custom}"
                
                if inclure_specialite and spec_combo:
                    term = f"{term} AND {TRAD[spec_combo]}"
                    spec_utilisee = spec_combo
                else:
                    spec_utilisee = "Personnalis√©"
            
            query_parts = [term]
            query_parts.append(f"{date_debut.strftime('%Y/%m/%d')}:{date_fin.strftime('%Y/%m/%d')}[pdat]")
            
            if "PDF complets" in mode_contenu:
                query_parts.append("free full text[sb]")
            
            # Gestion journaux
            if journal_selectionne == "SPECIALITE":
                journaux = JOURNAUX_SPECIALITE.get(spec_utilisee if mode_recherche == "Par sp√©cialit√©" else spec_combo, [])
                if journaux:
                    journaux_q = " OR ".join([f'"{j}"[Journal]' for j in journaux])
                    query_parts.append(f"({journaux_q})")
            elif journal_selectionne != "TOUS":
                query_parts.append(f'"{journal_selectionne}"[Journal]')
            
            if TYPES_ETUDE[type_etude]:
                query_parts.append(f"{TYPES_ETUDE[type_etude]}[ptyp]")
            
            query = " AND ".join(query_parts)
            
            # AFFICHER la requ√™te compl√®te
            with st.expander("üîç Requ√™te PubMed compl√®te"):
                st.code(query, language="text")
                st.caption("Cette requ√™te est envoy√©e √† PubMed pour rechercher les articles")
            
            base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {"db": "pubmed", "term": query, "retmode": "json", "retmax": nb_max, "sort": "date"}
            
            try:
                with st.spinner("üîé Recherche en cours sur PubMed..."):
                    response = requests.get(base_url, params=params, timeout=15)
                
                if response.status_code != 200:
                    st.error(f"Erreur: {response.status_code}")
                    st.stop()
                
                data = response.json()
                ids = data.get("esearchresult", {}).get("idlist", [])
                count = data.get("esearchresult", {}).get("count", "0")
                
                if not ids:
                    st.warning(f"‚ö†Ô∏è Aucun article trouv√©")
                    
                    st.info("""
**Suggestions pour am√©liorer les r√©sultats:**

1. **√âlargir la p√©riode** (ex: 2020-2025)
2. **Retirer les filtres restrictifs:**
   - D√©sactiver "PDF complets uniquement"
   - Mettre "Tous les journaux"
   - Retirer le filtre type d'√©tude
3. **Modifier les mots-cl√©s:**
   - Essayer des synonymes
   - Utiliser des termes plus g√©n√©raux
   - Retirer les accents

**Exemple:** Au lieu de "dysm√©norrh√©e", essayez "douleur menstruelle"
                    """)
                    
                    with st.expander("üîç V√©rifier la traduction"):
                        st.markdown(f"**Votre recherche:** {mots_cles_custom if mode_recherche == 'Par mots-cl√©s' else spec_fr}")
                        st.markdown(f"**Terme utilis√© sur PubMed:** `{term}`")
                        st.markdown(f"**Requ√™te compl√®te:** `{query}`")
                        st.markdown("""
**Conseil:** V√©rifiez que le terme anglais est correct. 
Par exemple, "dysmenorrhea" devrait donner des r√©sultats.
                        """)
                    
                    st.stop()
                
                st.success(f"‚úÖ {count} articles trouv√©s - Affichage de {len(ids)}")
                
                with st.spinner("R√©cup√©ration..."):
                    articles_preview = recuperer_titres_rapides(ids, traduire_titres=traduire_titres)
                
                st.session_state.articles_previsualises = articles_preview
                st.session_state.info_recherche = {
                    'display_term': display_term,
                    'periode': f"du {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}",
                    'spec': spec_utilisee,
                    'mode_traduction': 'gemini'
                }
                
                st.session_state.mode_etape = 2
                st.rerun()
            except Exception as e:
                st.error(f"Erreur: {str(e)}")
    
    elif st.session_state.mode_etape == 2:
        st.header("üìë √âtape 2 : S√©lection")
        
        st.info(f"{st.session_state.info_recherche['display_term']} | {st.session_state.info_recherche['periode']}")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ Tout s√©lectionner"):
                for i in range(len(st.session_state.articles_previsualises)):
                    st.session_state[f"select_{i}"] = True
                st.rerun()
        with col2:
            if st.button("‚Ü©Ô∏è Nouvelle recherche"):
                st.session_state.mode_etape = 1
                st.session_state.articles_previsualises = []
                st.rerun()
        
        st.divider()
        
        articles_sel = []
        
        for i, article in enumerate(st.session_state.articles_previsualises):
            col_c, col_i = st.columns([0.1, 0.9])
            with col_c:
                selected = st.checkbox("", key=f"select_{i}", label_visibility="collapsed")
            with col_i:
                st.markdown(f"**{i+1}. {article['title_fr']}**")
                st.markdown(f"üì∞ {article['journal']} | üìÖ {article['date_pub']} | [PMID {article['pmid']}](https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/)")
            
            if selected:
                articles_sel.append(article['pmid'])
            st.divider()
        
        st.markdown(f"**{len(articles_sel)} s√©lectionn√©(s)**")
        
        if 0 < len(articles_sel) <= 20:
            if st.button("üöÄ ANALYSER", type="primary", use_container_width=True):
                st.session_state.analyses_individuelles = {}
                
                for idx, pmid in enumerate(articles_sel):
                    st.subheader(f"üìÑ Article {idx+1}/{len(articles_sel)}")
                    
                    article_info = next((a for a in st.session_state.articles_previsualises if a['pmid'] == pmid), None)
                    if not article_info:
                        continue
                    
                    st.markdown(f"**{article_info['title_fr']}**")
                    st.markdown(f"[üîó Voir sur PubMed](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)")
                    
                    status = st.empty()
                    
                    def callback(msg):
                        status.info(msg)
                    
                    pdf_texte, erreur = telecharger_et_extraire_pdf(pmid, progress_callback=callback)
                    status.empty()
                    
                    if pdf_texte:
                        st.success(f"‚úÖ PDF extrait et traduit ({len(pdf_texte)} car.)")
                        
                        with st.expander("üìÑ Lire le PDF traduit"):
                            st.text_area("", pdf_texte, height=400, key=f"pdf_{pmid}")
                        
                        with st.spinner("ü§ñ Analyse IA..."):
                            try:
                                genai.configure(api_key=G_KEY)
                                model = genai.GenerativeModel('gemini-2.0-flash-exp')
                                
                                prompt = f"""Analyse m√©dicale approfondie.

Titre: {article_info['title_fr']}

{pdf_texte}

Analyse structur√©e:
## Objectif
## M√©thodologie
## R√©sultats principaux
## Implications cliniques
## Limites
## Conclusion"""
                                
                                response = model.generate_content(prompt)
                                analyse = response.text
                                
                                st.markdown("### ü§ñ Analyse IA")
                                st.markdown(analyse)
                                
                                st.session_state.analyses_individuelles[pmid] = {
                                    'pmid': pmid,
                                    'title_fr': article_info['title_fr'],
                                    'journal': article_info['journal'],
                                    'year': article_info['year'],
                                    'date_pub': article_info['date_pub'],
                                    'pdf_texte_fr': pdf_texte,
                                    'analyse_ia': analyse
                                }
                            except Exception as e:
                                st.error(f"Erreur analyse: {str(e)}")
                    else:
                        st.error(f"‚ùå {erreur}")
                        st.info(f"üí° L'article est peut-√™tre accessible via votre institution : [Voir sur PubMed](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)")
                    
                    st.divider()
                
                if st.session_state.analyses_individuelles:
                    st.session_state.mode_etape = 3
                    st.rerun()
    
    elif st.session_state.mode_etape == 3:
        st.header("üìö √âtape 3 : S√©lection finale")
        
        articles_finaux_ids = []
        
        for pmid, data in st.session_state.analyses_individuelles.items():
            col_c, col_i = st.columns([0.1, 0.9])
            with col_c:
                include = st.checkbox("", key=f"final_{pmid}", value=True, label_visibility="collapsed")
            with col_i:
                st.markdown(f"**{data['title_fr']}**")
                st.caption(f"{data['journal']} | {data['date_pub']}")
                with st.expander("ü§ñ Voir l'analyse"):
                    st.markdown(data['analyse_ia'])
            
            if include:
                articles_finaux_ids.append(pmid)
            st.divider()
        
        if articles_finaux_ids:
            st.success(f"‚úÖ {len(articles_finaux_ids)} s√©lectionn√©(s)")
            
            if st.button("üì¶ G√âN√âRER LES FICHIERS", type="primary", use_container_width=True):
                articles_finaux = [st.session_state.analyses_individuelles[pmid] for pmid in articles_finaux_ids]
                
                with st.spinner("G√©n√©ration..."):
                    pdf_final = generer_pdf_selectionne(
                        st.session_state.info_recherche['spec'],
                        st.session_state.info_recherche['periode'],
                        articles_finaux
                    )
                    notebooklm = generer_notebooklm_selectionne(articles_finaux)
                
                st.session_state.fichiers_finaux = {
                    'pdf': pdf_final,
                    'notebooklm': notebooklm,
                    'articles': articles_finaux
                }
                
                st.session_state.mode_etape = 4
                st.rerun()
    
    elif st.session_state.mode_etape == 4:
        st.header("üéâ Veille termin√©e!")
        
        st.success(f"‚úÖ {len(st.session_state.fichiers_finaux['articles'])} article(s) analys√©(s)")
        
        st.subheader("üìã R√©capitulatif")
        for i, article in enumerate(st.session_state.fichiers_finaux['articles'], 1):
            with st.expander(f"üìÑ Article {i} - {article['title_fr'][:60]}..."):
                st.markdown(f"**Journal:** {article['journal']} ({article['year']})")
                st.markdown(f"**PMID:** [{article['pmid']}](https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/)")
                st.markdown("### ü§ñ Analyse")
                st.markdown(article['analyse_ia'])
        
        st.divider()
        st.subheader("üì• T√©l√©chargements")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                "üìÑ T√©l√©charger PDF",
                st.session_state.fichiers_finaux['pdf'],
                f"veille_{datetime.now().strftime('%Y%m%d')}.pdf",
                mime="application/pdf",
                use_container_width=True
            )
        
        with col2:
            with st.expander("üìã Voir le texte NotebookLM"):
                st.text_area(
                    "Copier/coller dans NotebookLM:",
                    st.session_state.fichiers_finaux['notebooklm'],
                    height=400
                )
            
            st.download_button(
                "üíæ T√©l√©charger NotebookLM",
                st.session_state.fichiers_finaux['notebooklm'],
                f"podcast_{datetime.now().strftime('%Y%m%d')}.txt",
                use_container_width=True
            )
        
        st.info("üí° **Mobile** : Utilisez l'expander ci-dessus pour copier/coller le texte")
        st.link_button("üîó Ouvrir NotebookLM", "https://notebooklm.google.com", use_container_width=True)
        
        if st.button("üîÑ Nouvelle recherche", use_container_width=True):
            st.session_state.mode_etape = 1
            st.session_state.articles_previsualises = []
            st.session_state.analyses_individuelles = {}
            st.session_state.fichiers_finaux = {}
            st.rerun()

with tab2:
    st.header("üîó Sources compl√©mentaires")
    
    spec_src = st.selectbox("Choisir une sp√©cialit√©:", list(SOURCES_PAR_SPECIALITE.keys()))
    
    st.markdown(f"### {len(SOURCES_PAR_SPECIALITE[spec_src])} sources pour {spec_src}")
    
    for nom, info in SOURCES_PAR_SPECIALITE[spec_src].items():
        with st.expander(f"üìö {nom}"):
            st.markdown(f"**{info['description']}**")
            st.link_button("üè† Site officiel", info['url'])
            
            mots = st.text_input("Rechercher dans cette source:", key=f"src_{nom}")
            if mots:
                st.link_button("üîç Lancer la recherche", f"{info['recherche']}{mots}")

with tab3:
    st.header("‚öôÔ∏è Configuration")
    
    st.markdown("""
## üåê DeepL Pro+

**Tarif:** 29,99‚Ç¨/mois  
**Volume:** 1 million caract√®res/mois

### Installation
1. S'inscrire sur https://www.deepl.com/pro#developer
2. Choisir "API Pro+"
3. Copier la cl√© API
4. Ajouter dans Settings ‚Üí Secrets:
```toml
DEEPL_KEY = "votre-cl√©-ici"
```

### R√©siliation
Simple et rapide : Account ‚Üí Subscription ‚Üí Cancel  
‚úÖ Sans engagement
    """)
    
    if DEEPL_KEY:
        st.success("‚úÖ DeepL Pro+ configur√©")
    else:
        st.info("‚ÑπÔ∏è Traduction : Gemini 2.0 Flash (gratuit)")

st.caption("üíä Veille m√©dicale professionnelle | Gemini 2.0 Flash")
