import streamlit as st
import google.generativeai as genai
import requests
import json
from datetime import datetime
import xml.etree.ElementTree as ET
from fpdf import FPDF
import io

st.set_page_config(page_title="Veille M√©dicale Pro", layout="wide")

# R√©cup√©ration de la cl√© Gemini
try:
    G_KEY = st.secrets["GEMINI_KEY"]
except:
    st.error("‚ö†Ô∏è Cl√© GEMINI_KEY manquante dans les secrets")
    st.stop()

# Sp√©cialit√©s √©tendues
TRAD = {
    "Gyn√©cologie": "Gynecology",
    "Obst√©trique": "Obstetrics",
    "Anesth√©sie-R√©animation": "Anesthesiology",
    "M√©decine G√©n√©rale": "General Medicine",
    "Endocrinologie": "Endocrinology",
    "Cardiologie": "Cardiology",
    "Neurologie": "Neurology",
    "Oncologie": "Oncology",
    "P√©diatrie": "Pediatrics"
   
   
}

# Types d'√©tudes
TYPES_ETUDE = {
    "Tous": "",
    "Essais cliniques": "Clinical Trial",
    "M√©ta-analyses": "Meta-Analysis",
    "Revues syst√©matiques": "Systematic Review",
    "√âtudes de cohorte": "Cohort Studies",
    "√âtudes cas-t√©moins": "Case-Control Studies"
}

# Initialiser l'historique dans session_state
if 'historique' not in st.session_state:
    st.session_state.historique = []

# Fonction pour traduire les mots-cl√©s fran√ßais en anglais
def traduire_mots_cles(mots_cles_fr, api_key):
    """Traduit les mots-cl√©s fran√ßais en anglais m√©dical pour PubMed"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        prompt = f"""Traduis ces mots-cl√©s m√©dicaux fran√ßais en anglais m√©dical pr√©cis pour une recherche PubMed.
Retourne UNIQUEMENT les termes anglais, sans explication.

Mots-cl√©s fran√ßais: {mots_cles_fr}

Termes anglais pour PubMed:"""
        
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Traduction automatique √©chou√©e, utilisation des termes originaux")
        return mots_cles_fr

# Fonction pour traduire un texte avec Gemini
def traduire_texte(texte, api_key):
    """Traduit un texte en fran√ßais avec Gemini"""
    if not texte or texte == "R√©sum√© non disponible":
        return texte
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        prompt = f"""Traduis ce r√©sum√© m√©dical en fran√ßais de mani√®re professionnelle et pr√©cise. 
Conserve tous les termes m√©dicaux importants avec leur √©quivalent fran√ßais entre parenth√®ses si n√©cessaire.

Texte √† traduire:
{texte}

Traduction en fran√ßais:"""
        
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"[Erreur de traduction: {str(e)}]"

# Fonction pour cr√©er un PDF enrichi
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, 'Veille Medicale - Synthese IA', 0, 1, 'C')
        self.ln(5)
    
    def footer(self):
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')
    
    def section_title(self, title):
        self.set_font('Arial', 'B', 14)
        self.set_fill_color(200, 220, 255)
        self.cell(0, 10, title, 0, 1, 'L', 1)
        self.ln(3)
    
    def subsection_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 8, title, 0, 1, 'L')
        self.ln(1)
    
    def body_text(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 5, text)
        self.ln(2)

def generer_pdf_complet(spec, annee, nb_articles, pmids, synthese, articles_data):
    """G√©n√®re un PDF complet avec synth√®se IA et articles d√©taill√©s"""
    pdf = PDF()
    pdf.add_page()
    
    # PAGE DE GARDE
    pdf.set_font('Arial', 'B', 20)
    pdf.ln(30)
    pdf.cell(0, 15, 'VEILLE MEDICALE', 0, 1, 'C')
    pdf.set_font('Arial', 'B', 16)
    pdf.cell(0, 10, 'Synthese et Articles', 0, 1, 'C')
    pdf.ln(20)
    
    pdf.set_font('Arial', '', 12)
    pdf.cell(0, 8, f'Specialite: {spec}', 0, 1, 'C')
    pdf.cell(0, 8, f'Periode: {annee}', 0, 1, 'C')
    pdf.cell(0, 8, f'Nombre d\'articles: {nb_articles}', 0, 1, 'C')
    pdf.cell(0, 8, f'Date de generation: {datetime.now().strftime("%d/%m/%Y %H:%M")}', 0, 1, 'C')
    
    # PARTIE 1 : SYNTH√àSE IA
    pdf.add_page()
    pdf.section_title('PARTIE 1 : SYNTHESE PAR INTELLIGENCE ARTIFICIELLE')
    
    # Nettoyer et encoder le texte de la synth√®se
    try:
        synthese_clean = synthese.encode('latin-1', 'ignore').decode('latin-1')
    except:
        synthese_clean = synthese.encode('ascii', 'ignore').decode('ascii')
    
    pdf.body_text(synthese_clean)
    
    # PARTIE 2 : ARTICLES D√âTAILL√âS
    pdf.add_page()
    pdf.section_title('PARTIE 2 : ARTICLES ETUDIES')
    pdf.ln(5)
    
    for i, article in enumerate(articles_data, 1):
        # Titre de l'article
        pdf.subsection_title(f'Article {i}')
        
        # PMID
        pdf.set_font('Arial', 'B', 10)
        pdf.cell(0, 6, f'PMID: {article["pmid"]}', 0, 1)
        
        # Titre
        pdf.set_font('Arial', 'B', 10)
        pdf.cell(0, 6, 'Titre:', 0, 1)
        try:
            title_clean = article['title'].encode('latin-1', 'ignore').decode('latin-1')
        except:
            title_clean = article['title'].encode('ascii', 'ignore').decode('ascii')
        pdf.set_font('Arial', '', 10)
        pdf.multi_cell(0, 5, title_clean)
        pdf.ln(2)
        
        # Auteurs
        if article['authors']:
            pdf.set_font('Arial', 'B', 10)
            pdf.cell(0, 6, 'Auteurs:', 0, 1)
            pdf.set_font('Arial', '', 10)
            authors_text = ', '.join(article['authors'])
            try:
                authors_clean = authors_text.encode('latin-1', 'ignore').decode('latin-1')
            except:
                authors_clean = authors_text.encode('ascii', 'ignore').decode('ascii')
            pdf.multi_cell(0, 5, authors_clean)
            pdf.ln(2)
        
        # Journal et ann√©e
        pdf.set_font('Arial', 'B', 10)
        pdf.cell(0, 6, 'Publication:', 0, 1)
        pdf.set_font('Arial', '', 10)
        try:
            journal_clean = article['journal'].encode('latin-1', 'ignore').decode('latin-1')
        except:
            journal_clean = article['journal'].encode('ascii', 'ignore').decode('ascii')
        pdf.cell(0, 5, f'{journal_clean} ({article["year"]})', 0, 1)
        pdf.ln(2)
        
        # R√©sum√© en fran√ßais
        pdf.set_font('Arial', 'B', 10)
        pdf.cell(0, 6, 'Resume (Francais):', 0, 1)
        pdf.set_font('Arial', '', 9)
        try:
            abstract_clean = article['abstract_fr'].encode('latin-1', 'ignore').decode('latin-1')
        except:
            abstract_clean = article['abstract_fr'].encode('ascii', 'ignore').decode('ascii')
        pdf.multi_cell(0, 4, abstract_clean)
        pdf.ln(3)
        
        # Lien PubMed
        pdf.set_font('Arial', 'I', 9)
        pdf.cell(0, 5, f'Lien: https://pubmed.ncbi.nlm.nih.gov/{article["pmid"]}/', 0, 1)
        
        # S√©parateur
        pdf.ln(5)
        pdf.set_draw_color(180, 180, 180)
        pdf.line(10, pdf.get_y(), 200, pdf.get_y())
        pdf.ln(5)
        
        # Nouvelle page tous les 2-3 articles pour √©viter la surcharge
        if i % 2 == 0 and i < len(articles_data):
            pdf.add_page()
    
    # TABLE DES MATI√àRES DES PMIDs (√† la fin)
    pdf.add_page()
    pdf.section_title('INDEX DES ARTICLES PAR PMID')
    pdf.ln(3)
    
    pdf.set_font('Arial', '', 10)
    for i, article in enumerate(articles_data, 1):
        try:
            title_short = article['title'][:80].encode('latin-1', 'ignore').decode('latin-1')
        except:
            title_short = article['title'][:80].encode('ascii', 'ignore').decode('ascii')
        pdf.cell(0, 6, f'{i}. PMID {article["pmid"]}: {title_short}...', 0, 1)
    
    # Sauvegarder en m√©moire
    pdf_output = io.BytesIO()
    pdf_string = pdf.output(dest='S').encode('latin-1')
    pdf_output.write(pdf_string)
    pdf_output.seek(0)
    
    return pdf_output.getvalue()

def recuperer_abstracts(pmids, traduire=False, api_key=None):
    """R√©cup√®re les r√©sum√©s complets depuis PubMed"""
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    
    params = {
        "db": "pubmed",
        "id": ",".join(pmids),
        "retmode": "xml",
        "rettype": "abstract"
    }
    
    try:
        response = requests.get(base_url, params=params, timeout=15)
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            articles_data = []
            
            for article in root.findall('.//PubmedArticle'):
                pmid = article.find('.//PMID').text if article.find('.//PMID') is not None else "N/A"
                
                title_elem = article.find('.//ArticleTitle')
                title = title_elem.text if title_elem is not None else "Titre non disponible"
                
                abstract_elem = article.find('.//AbstractText')
                abstract = abstract_elem.text if abstract_elem is not None else "R√©sum√© non disponible"
                
                # Traduire si demand√©
                abstract_fr = abstract
                if traduire and abstract != "R√©sum√© non disponible" and api_key:
                    abstract_fr = traduire_texte(abstract, api_key)
                
                # Auteurs
                authors = []
                for author in article.findall('.//Author'):
                    lastname = author.find('LastName')
                    forename = author.find('ForeName')
                    if lastname is not None:
                        name = lastname.text
                        if forename is not None:
                            name = f"{forename.text} {name}"
                        authors.append(name)
                
                # Journal
                journal_elem = article.find('.//Journal/Title')
                journal = journal_elem.text if journal_elem is not None else "Journal non disponible"
                
                # Ann√©e
                year_elem = article.find('.//PubDate/Year')
                year = year_elem.text if year_elem is not None else "N/A"
                
                articles_data.append({
                    'pmid': pmid,
                    'title': title,
                    'abstract': abstract,
                    'abstract_fr': abstract_fr,
                    'authors': authors,  # Tous les auteurs pour le PDF
                    'journal': journal,
                    'year': year
                })
            
            return articles_data
    except Exception as e:
        st.warning(f"Erreur lors de la r√©cup√©ration des r√©sum√©s: {str(e)}")
        return []
    
    return []

def sauvegarder_recherche(spec, annee, type_etude, langue, pmids, synthese, mots_cles=""):
    """Sauvegarde la recherche dans l'historique"""
    recherche = {
        'date': datetime.now().strftime("%d/%m/%Y %H:%M"),
        'specialite': spec,
        'annee': annee,
        'type_etude': type_etude,
        'langue': langue,
        'mots_cles': mots_cles,
        'nb_articles': len(pmids),
        'pmids': pmids,
        'synthese': synthese
    }
    st.session_state.historique.insert(0, recherche)
    if len(st.session_state.historique) > 20:
        st.session_state.historique = st.session_state.historique[:20]

# Interface principale
st.title("ü©∫ Veille M√©dicale Professionnelle")
st.markdown("*Analyse avanc√©e des publications PubMed avec IA*")

# Tabs pour organiser l'interface
tab1, tab2 = st.tabs(["üîç Nouvelle Recherche", "üìö Historique"])

with tab1:
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # Mode de recherche
        mode_recherche = st.radio("Mode de recherche", ["Par sp√©cialit√©", "Par mots-cl√©s"], horizontal=True)
        
        if mode_recherche == "Par sp√©cialit√©":
            spec_fr = st.selectbox("üè• Sp√©cialit√© m√©dicale", list(TRAD.keys()))
            mots_cles_custom = ""
            mots_cles_originaux = ""
        else:
            spec_fr = None
            mots_cles_custom = st.text_area(
                "üîé Mots-cl√©s de recherche",
                placeholder="Exemples:\n- diab√®te de type 2 traitement\n- cancer du sein immunoth√©rapie\n- hypertension art√©rielle nouvelles recommandations",
                help="Entrez vos mots-cl√©s en fran√ßais ou en anglais. S√©parez-les par des virgules ou sur des lignes diff√©rentes.",
                height=100
            )
            mots_cles_originaux = mots_cles_custom
        
        st.subheader("üìÖ P√©riode")
        col1, col2 = st.columns(2)
        with col1:
            annee_debut = st.selectbox("De", ["2020", "2021", "2022", "2023", "2024", "2025"], index=4)
        with col2:
            annee_fin = st.selectbox("√Ä", ["2020", "2021", "2022", "2023", "2024", "2025"], index=4)
        
        st.subheader("üî¨ Filtres avanc√©s")
        type_etude = st.selectbox("Type d'√©tude", list(TYPES_ETUDE.keys()))
        
        langue = st.selectbox("Langue", [
            "Toutes",
            "Anglais",
            "Fran√ßais",
            "Espagnol",
            "Allemand"
        ])
        
        # Option de traduction
        traduire_abstracts = st.checkbox("üåê Traduire les r√©sum√©s en fran√ßais", value=True)
        
        nb = st.slider("üìä Nombre d'articles", 1, 20, 5)
        
        st.divider()
        st.caption("üî¨ Donn√©es: PubMed/NCBI")
        st.caption("ü§ñ IA: Google Gemini 2.5")
        st.caption("üåê Traduction automatique FR‚ÜîEN")

    if st.button("üîç Lancer la recherche", type="primary", use_container_width=True):
        
        # Validation
        if mode_recherche == "Par mots-cl√©s" and not mots_cles_custom:
            st.error("‚ö†Ô∏è Veuillez entrer des mots-cl√©s de recherche")
            st.stop()
        
        # Construction de la requ√™te
        if mode_recherche == "Par sp√©cialit√©":
            term = TRAD[spec_fr]
            display_term = spec_fr
            mots_cles_traduits = None
        else:
            with st.spinner("üåê Traduction des mots-cl√©s en anglais m√©dical..."):
                mots_cles_traduits = traduire_mots_cles(mots_cles_custom, G_KEY)
            
            term = mots_cles_traduits
            display_term = f"Mots-cl√©s: {mots_cles_custom}"
            st.info(f"üîÑ **Traduction pour PubMed:** {mots_cles_traduits}")
        
        # Construction de la requ√™te avec filtres
        query_parts = [term]
        
        if annee_debut == annee_fin:
            query_parts.append(f"{annee_debut}[pdat]")
        else:
            query_parts.append(f"{annee_debut}:{annee_fin}[pdat]")
        
        if TYPES_ETUDE[type_etude]:
            query_parts.append(f"{TYPES_ETUDE[type_etude]}[ptyp]")
        
        langue_codes = {
            "Anglais": "eng",
            "Fran√ßais": "fre",
            "Espagnol": "spa",
            "Allemand": "ger"
        }
        if langue != "Toutes":
            query_parts.append(f"{langue_codes[langue]}[la]")
        
        query = " AND ".join(query_parts)
        
        base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
        
        params = {
            "db": "pubmed",
            "term": query,
            "retmode": "json",
            "retmax": nb,
            "sort": "relevance"
        }
        
        with st.expander("üîç D√©tails de la requ√™te PubMed"):
            st.write(f"**Recherche:** {display_term}")
            if mots_cles_traduits:
                st.write(f"**Mots-cl√©s originaux (FR):** {mots_cles_custom}")
                st.write(f"**Mots-cl√©s traduits (EN):** {mots_cles_traduits}")
            st.code(query)
        
        # √âTAPE 1 : Recherche PubMed
        try:
            with st.spinner(f"üîé Recherche en cours sur PubMed..."):
                response = requests.get(
                    base_url,
                    params=params,
                    headers={'User-Agent': 'Streamlit Medical Research App'},
                    timeout=15
                )
            
            if response.status_code != 200:
                st.error(f"‚ùå Erreur PubMed: {response.status_code}")
                st.stop()
            
            data = response.json()
            search_result = data.get("esearchresult", {})
            ids = search_result.get("idlist", [])
            count = search_result.get("count", "0")
            
            if not ids:
                st.warning(f"‚ö†Ô∏è Aucun article trouv√© avec ces crit√®res")
                st.info("üí° **Suggestions:**")
                st.write("- Essayez des mots-cl√©s plus g√©n√©raux")
                st.write("- √âlargissez la p√©riode de recherche")
                st.write("- Retirez certains filtres avanc√©s")
                st.stop()
            
            st.success(f"‚úÖ {count} articles trouv√©s - Affichage de {len(ids)}")
            
            # √âTAPE 2 : R√©cup√©ration des r√©sum√©s complets
            message_traduction = "üìÑ R√©cup√©ration et traduction des r√©sum√©s..." if traduire_abstracts else "üìÑ R√©cup√©ration des r√©sum√©s..."
            with st.spinner(message_traduction):
                articles_complets = recuperer_abstracts(ids, traduire=traduire_abstracts, api_key=G_KEY)
            
            if articles_complets:
                st.subheader("üìö Articles avec r√©sum√©s")
                
                for i, article in enumerate(articles_complets, 1):
                    with st.expander(f"**Article {i}** - {article['title'][:100]}..."):
                        st.markdown(f"**PMID:** [{article['pmid']}](https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/)")
                        st.markdown(f"**Journal:** {article['journal']} ({article['year']})")
                        if article['authors']:
                            st.markdown(f"**Auteurs:** {', '.join(article['authors'][:3])}")
                        
                        if traduire_abstracts:
                            st.markdown("**üìñ R√©sum√© (Fran√ßais):**")
                            st.write(article['abstract_fr'])
                            
                            with st.expander("üî§ Voir le r√©sum√© original (Anglais)"):
                                st.write(article['abstract'])
                        else:
                            st.markdown("**üìñ R√©sum√©:**")
                            st.write(article['abstract'])
            else:
                st.subheader("üìö Articles s√©lectionn√©s")
                cols = st.columns(2)
                for i, pmid in enumerate(ids):
                    col = cols[i % 2]
                    with col:
                        st.markdown(f"**{i+1}.** [PubMed ID: {pmid}](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)")
            
            st.divider()
            
            # √âTAPE 3 : Analyse IA
            st.subheader("ü§ñ Synth√®se par Intelligence Artificielle")
            
            with st.spinner("‚è≥ Analyse approfondie en cours..."):
                try:
                    genai.configure(api_key=G_KEY)
                    model = genai.GenerativeModel('gemini-2.5-flash')
                    
                    contexte_articles = ""
                    if articles_complets:
                        for art in articles_complets:
                            resume_a_utiliser = art['abstract_fr'] if traduire_abstracts else art['abstract']
                            contexte_articles += f"\n\nPMID {art['pmid']}:\nTitre: {art['title']}\nR√©sum√©: {resume_a_utiliser}\n"
                    
                    liens_articles = "\n".join([f"- https://pubmed.ncbi.nlm.nih.gov/{pmid}/" for pmid in ids])
                    
                    specialite_texte = spec_fr if mode_recherche == "Par sp√©cialit√©" else f"Recherche par mots-cl√©s: {mots_cles_custom}"
                    
                    prompt = f"""Tu es un m√©decin expert r√©alisant une veille scientifique approfondie.

Analyse ces {len(ids)} articles r√©cents de PubMed.

**Crit√®res de recherche:**
- {specialite_texte}
- P√©riode: {annee_debut} √† {annee_fin}
- Type d'√©tude: {type_etude}
- Langue: {langue}

**Articles avec r√©sum√©s complets:**
{contexte_articles}

**PMIDs:** {', '.join(ids)}

R√©dige une synth√®se professionnelle d√©taill√©e en fran√ßais avec:

## üìä Vue d'ensemble
Pr√©sente le contexte g√©n√©ral, la m√©thodologie des √©tudes et leur port√©e

## üî¨ Tendances et th√©matiques principales
Identifie les sujets dominants, les approches innovantes et les paradigmes √©mergents

## üí° D√©couvertes et r√©sultats notables
D√©taille les r√©sultats significatifs, les avanc√©es importantes et les donn√©es cl√©s

## üè• Implications pour la pratique clinique
Explique les applications concr√®tes, recommandations pratiques et impact sur les protocoles

## ‚ö†Ô∏è Limites et perspectives
Mentionne les limites m√©thodologiques et les axes de recherche futurs

## üîó Sources
{liens_articles}

Utilise un ton professionnel, scientifique mais accessible. Cite les PMIDs pertinents pour chaque point important."""
                    
                    response_ia = model.generate_content(prompt)
                    synthese_texte = response_ia.text
                    
                    st.markdown(synthese_texte)
                    
                    sauvegarder_recherche(
                        spec_fr if mode_recherche == "Par sp√©cialit√©" else "Recherche personnalis√©e",
                        f"{annee_debut}-{annee_fin}",
                        type_etude,
                        langue,
                        ids,
                        synthese_texte,
                        mots_cles_originaux
                    )
                    
                    st.success("‚úÖ Synth√®se g√©n√©r√©e et sauvegard√©e !")
                    
                    # Boutons de t√©l√©chargement
                    col1, col2 = st.columns(2)
                    
                    nom_fichier = spec_fr if mode_recherche == "Par sp√©cialit√©" else "recherche_personnalisee"
                    
                    with col1:
                        st.download_button(
                            label="üì• T√©l√©charger (.txt)",
                            data=synthese_texte,
                            file_name=f"synthese_{nom_fichier}_{annee_debut}-{annee_fin}.txt",
                            mime="text/plain"
                        )
                    
                    with col2:
                        # G√©n√©rer le PDF COMPLET avec articles
                        with st.spinner("üìÑ G√©n√©ration du PDF complet..."):
                            pdf_bytes = generer_pdf_complet(
                                display_term, 
                                f"{annee_debut}-{annee_fin}", 
                                len(ids), 
                                ids, 
                                synthese_texte,
                                articles_complets
                            )
                        st.download_button(
                            label="üìÑ T√©l√©charger PDF Complet (Synth√®se + Articles)",
                            data=pdf_bytes,
                            file_name=f"veille_medicale_complete_{nom_fichier}_{annee_debut}-{annee_fin}.pdf",
                            mime="application/pdf"
                        )
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'analyse IA: {str(e)}")
                    st.info("üí° Les articles et r√©sum√©s restent accessibles ci-dessus")
        
        except requests.exceptions.Timeout:
            st.error("‚ùå D√©lai d√©pass√© - PubMed ne r√©pond pas")
            st.info("R√©essayez dans quelques instants")
            
        except Exception as e:
            st.error(f"‚ùå Erreur technique: {str(e)}")

with tab2:
    st.header("üìö Historique des recherches")
    
    if not st.session_state.historique:
        st.info("Aucune recherche enregistr√©e pour le moment.")
    else:
        st.write(f"**{len(st.session_state.historique)} recherche(s) sauvegard√©e(s)**")
        
        for i, rech in enumerate(st.session_state.historique):
            titre_historique = f"üîç {rech['date']} - {rech['specialite']} ({rech['annee']}) - {rech['nb_articles']} articles"
            if rech.get('mots_cles'):
                titre_historique += f" - Mots-cl√©s: {rech['mots_cles'][:50]}..."
            
            with st.expander(titre_historique):
                st.markdown(f"**Sp√©cialit√©:** {rech['specialite']}")
                if rech.get('mots_cles'):
                    st.markdown(f"**Mots-cl√©s:** {rech['mots_cles']}")
                st.markdown(f"**Ann√©e:** {rech['annee']}")
                st.markdown(f"**Type d'√©tude:** {rech['type_etude']}")
                st.markdown(f"**Langue:** {rech['langue']}")
                st.markdown(f"**Nombre d'articles:** {rech['nb_articles']}")
                st.markdown(f"**PMIDs:** {', '.join(rech['pmids'])}")
                
                st.divider()
                st.markdown("**Synth√®se IA:**")
                st.markdown(rech['synthese'])
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.download_button(
                        label="üì• TXT",
                        data=rech['synthese'],
                        file_name=f"synthese_historique_{i+1}.txt",
                        mime="text/plain",
                        key=f"txt_{i}"
                    )
                
                with col2:
                    # Note: Pour l'historique, on g√©n√®re un PDF simple (sans articles complets)
                    # car on n'a pas sauvegard√© les donn√©es compl√®tes des articles
                    pdf_simple = PDF()
                    pdf_simple.add_page()
                    pdf_simple.set_font('Arial', '', 10)
                    try:
                        synthese_clean = rech['synthese'].encode('latin-1', 'ignore').decode('latin-1')
                    except:
                        synthese_clean = rech['synthese'].encode('ascii', 'ignore').decode('ascii')
                    pdf_simple.multi_cell(0, 5, synthese_clean)
                    
                    pdf_output = io.BytesIO()
                    pdf_string = pdf_simple.output(dest='S').encode('latin-1')
                    pdf_output.write(pdf_string)
                    pdf_bytes_hist = pdf_output.getvalue()
                    
                    st.download_button(
                        label="üìÑ PDF",
                        data=pdf_bytes_hist,
                        file_name=f"synthese_historique_{i+1}.pdf",
                        mime="application/pdf",
                        key=f"pdf_{i}"
                    )
                
                with col3:
                    liens = "\n".join([f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/" for pmid in rech['pmids']])
                    st.download_button(
                        label="üîó Liens",
                        data=liens,
                        file_name=f"liens_articles_{i+1}.txt",
                        mime="text/plain",
                        key=f"liens_{i}"
                    )
        
        st.divider()
        if st.button("üóëÔ∏è Effacer l'historique", type="secondary"):
            st.session_state.historique = []
            st.success("Historique effac√© !")
            st.rerun()

st.markdown("---")
st.caption("üíä Application de veille m√©dicale professionnelle | PubMed + Gemini 2.5 | üåê Traduction FR‚ÜîEN automatique")
